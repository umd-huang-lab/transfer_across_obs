# Transfer RL across Observation Feature Spaces via Model-Based Regularization



This folder includes the DQN source code for the CartPole experiments (Figure 3 in our paper). The DQN implementation is mainly based on an online tutorial [(link)](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html).



To reproduce the results for the transfer learning, simply run the following command in the terminal.

```
bash pixel_cart.sh
```

Two folders "data" and "learned_models" will be created. In the "data" folder, there will be .png plots and log files for each setting. 

